{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1319dc6a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In the cell below we load the data in and split it into training and validating data. We also load the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9775f2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X_full = pd.read_csv('./input/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('./input/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing Price info, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Select categorical columns to perform Ordinal Encoding\n",
    "ord_categorical_cols = ['Street', 'Alley', 'ExterQual', 'ExterCond',\n",
    "                       'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "                       'BsmtFinType1', 'BsmtFinType2', 'HeatingQC',\n",
    "                       'CentralAir', 'KitchenQual', 'Functional',\n",
    "                       'FireplaceQu', 'GarageFinish', 'GarageQual',\n",
    "                       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence']\n",
    "\n",
    "# Select categorical columns to perform OneHotEncoding\n",
    "ohe_categorical_cols = [cname for cname in X_full.columns if \n",
    "                    X_full[cname].dtype == \"object\" and\n",
    "                    cname not in ord_categorical_cols]\n",
    "\n",
    "# For now we drop ohe columns ...\n",
    "X_full.drop(ohe_categorical_cols, axis=1, inplace=True)\n",
    "X_full.drop(ord_categorical_cols, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Split the data into training and validating\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59dacbe",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Transforming the data to `tensor` type so that we can use it in the `PyTorch` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe8f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = ord_categorical_cols + ohe_categorical_cols + numerical_cols\n",
    "my_cols = numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()\n",
    "\n",
    "X_deploy = X_full[my_cols].copy()\n",
    "y_deploy = y.copy()\n",
    "\n",
    "\n",
    "from torch import tensor\n",
    "\n",
    "X_train = tensor(X_train.to_numpy()).float()\n",
    "X_valid = tensor(X_valid.to_numpy()).float()\n",
    "y_train = tensor(y_train.values.reshape(-1,1)).float()\n",
    "y_valid = tensor(y_valid.values.reshape(-1,1)).float()\n",
    "\n",
    "X_test = tensor(X_test.to_numpy()).float()\n",
    "\n",
    "X_deploy = tensor(X_deploy.to_numpy()).float()\n",
    "y_deploy = tensor(y_deploy.values.reshape(-1,1)).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f3af8",
   "metadata": {},
   "source": [
    "### Creating the pipeline\n",
    "\n",
    "First we define the preproessing steps which describe how we handle the missing data. After trying different ways of dealing with missing data, the following work best:\n",
    "- Replace any missing numerical value with the `mean` value in a particular column.\n",
    "\n",
    "In this step, we also create the Regressor Neural Network model which we wrap in a `NeuralNetRegressor` object. Lastly, we bundle everything together into a ML Pipeline which we call `model_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb4cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[uninitialized](\n",
       "  module=<class '__main__.Regressor'>,\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Model Definition\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "\n",
    "        self.first_layer = nn.Linear(36, 26)\n",
    "        self.second_layer = nn.Linear(26,52)\n",
    "        self.final_layer = nn.Linear(52,1)\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        # For some weird reason .float() is needed here...\n",
    "        # Although the data has already been casted to float...\n",
    "        X = self.first_layer(x_batch.float())\n",
    "        X = F.relu(X)\n",
    "\n",
    "        X = self.second_layer(X)\n",
    "        X = F.relu(X)\n",
    "\n",
    "        return self.final_layer(X)\n",
    "\n",
    "## Declare Model\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "from torch import optim\n",
    "\n",
    "skorch_regressor = NeuralNetRegressor(module=Regressor, optimizer=optim.Adam, max_epochs=500, verbose=0)\n",
    "\n",
    "skorch_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 Pipeline(steps=[('imputer', SimpleImputer())])),\n",
       "                ('normalize', RobustScaler()),\n",
       "                ('model',\n",
       "                 <class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=Regressor(\n",
       "    (first_layer): Linear(in_features=36, out_features=26, bias=True)\n",
       "    (second_layer): Linear(in_features=26, out_features=52, bias=True)\n",
       "    (final_layer): Linear(in_features=52, out_features=1, bias=True)\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', numerical_transformer),\n",
    "                                 ('normalize', RobustScaler()),\n",
    "                                 ('model', skorch_regressor)])\n",
    "model_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE : 16703.05859375\n",
      "Test  MAE : 21337.0859375\n",
      "\n",
      "Train R^2 : 0.877506186505159\n",
      "Test  R^2 : 0.6845423939729588\n"
     ]
    }
   ],
   "source": [
    "### Evaluate Model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"Train MAE : {}\".format(mean_absolute_error(y_train, model_pipeline.predict(X_train).reshape(-1))))\n",
    "print(\"Test  MAE : {}\".format(mean_absolute_error(y_valid, model_pipeline.predict(X_valid).reshape(-1))))\n",
    "\n",
    "print(\"\\nTrain R^2 : {}\".format(model_pipeline.score(X_train, y_train)))\n",
    "print(\"Test  R^2 : {}\".format(model_pipeline.score(X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
