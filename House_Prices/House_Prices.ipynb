{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1319dc6a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In the cell below we load the data in and split it into training and validating data. We also load the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9775f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X_full = pd.read_csv('./input/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('./input/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing Price info, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Split the data into training and validating\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59dacbe",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Below we perform feature engineering (i.e deal with categorical columns and the missing data). We have two choices for dealing with categorical data:\n",
    "- Ordinal Encoding, where we assign an integer to each of the unique variables that appear in the column. For example if the variables appearing in the column are `['bad', 'neutral','good']`, then we can assign integers to each of them like this: `'bad'=0, 'neutral'=1, 'good'=2`.\n",
    "- One Hot Encoding, when there is no clear logical pattern as to which variable we should assign the highest integer. Instead, One Hot Encoding creates an extra dummy column for each unique variable appearing in a column and then fills that columns with `1` or `0` depending on whether that variable was present in the original column for that datapoint.\n",
    "\n",
    "After going through the description of each column in the dataset, we determine which categorical column is better suited for Ordinal Encoding and which is better suited for One Hot Encoding.  In contrast to the heavy work needed for the categorical columns, we only need to take care of the missing data for the numerical columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe8f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns to perform Ordinal Encoding\n",
    "# Add Utilities to ord somehow ['ELO', 'NoSeWa','NoSewr', 'AllPub']\n",
    "ord_categorical_cols = ['Street', 'Alley', 'ExterQual', 'ExterCond',\n",
    "                       'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "                       'BsmtFinType1', 'BsmtFinType2', 'HeatingQC',\n",
    "                       'CentralAir', 'KitchenQual', 'Functional',\n",
    "                       'FireplaceQu', 'GarageFinish', 'GarageQual',\n",
    "                       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence']\n",
    "\n",
    "# Select categorical columns to perform OneHotEncoding\n",
    "ohe_categorical_cols = [cname for cname in X_train_full.columns if \n",
    "                    X_train_full[cname].dtype == \"object\" and\n",
    "                    cname not in ord_categorical_cols]\n",
    "\n",
    "# TODO: Use the following specified order for Ordinal Encoding\n",
    "import array as arr\n",
    "specified_ordering = [[None, 'Grvl', 'Pave'],\n",
    "                      ['Grvl', 'Pave'],\n",
    "                      ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                      ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                      [None, 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                      [None, 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                      [None, 'No', 'Mn', 'Av', 'Gd'],\n",
    "                      [None, 'Unf', 'Lwq', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "                      [None, 'Unf', 'Lwq', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "                      ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                      ['N', 'Y'],\n",
    "                      ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                      ['Sal','Sev','Maj2','Maj1','Mod','Min2','Min1','Typ'],\n",
    "                      [None, 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                      [None, 'Unf', 'RFn', 'Fin'],\n",
    "                      [None, 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                      [None, 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                      ['N', 'P', 'Y'],\n",
    "                      [None, 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "                      [None, 'MnWw', 'GdWo', 'MnPrv', 'GdPrv']]\n",
    "\n",
    "#specified_ordering = [X_full[col].unique() for col in \n",
    "#                      ord_categorical_cols]\n",
    "\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = ord_categorical_cols + ohe_categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()\n",
    "\n",
    "X_deploy = X_full[my_cols].copy()\n",
    "y_deploy = y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8ce81",
   "metadata": {},
   "source": [
    "We can run the cell below to get a quick idea about what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53674906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ex</td>\n",
       "      <td>TA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Ex</td>\n",
       "      <td>...</td>\n",
       "      <td>774</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Gd</td>\n",
       "      <td>...</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Ex</td>\n",
       "      <td>...</td>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Ex</td>\n",
       "      <td>...</td>\n",
       "      <td>857</td>\n",
       "      <td>150</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Ex</td>\n",
       "      <td>...</td>\n",
       "      <td>843</td>\n",
       "      <td>468</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Street Alley ExterQual ExterCond BsmtQual BsmtCond BsmtExposure  \\\n",
       "Id                                                                    \n",
       "619   Pave   NaN        Ex        TA       Ex       TA           Av   \n",
       "871   Pave   NaN        TA        TA       TA       TA           No   \n",
       "93    Pave  Grvl        TA        Gd       Gd       TA           No   \n",
       "818   Pave   NaN        Gd        TA       Gd       TA           No   \n",
       "303   Pave   NaN        Gd        TA       Gd       TA           No   \n",
       "\n",
       "    BsmtFinType1 BsmtFinType2 HeatingQC  ... GarageArea WoodDeckSF  \\\n",
       "Id                                       ...                         \n",
       "619          GLQ          Unf        Ex  ...        774          0   \n",
       "871          Unf          Unf        Gd  ...        308          0   \n",
       "93           ALQ          Unf        Ex  ...        432          0   \n",
       "818          GLQ          Unf        Ex  ...        857        150   \n",
       "303          Unf          Unf        Ex  ...        843        468   \n",
       "\n",
       "    OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea MiscVal MoSold  \\\n",
       "Id                                                                            \n",
       "619         108             0         0         260        0       0      7   \n",
       "871           0             0         0           0        0       0      8   \n",
       "93            0            44         0           0        0       0      8   \n",
       "818          59             0         0           0        0       0      7   \n",
       "303          81             0         0           0        0       0      1   \n",
       "\n",
       "    YrSold  \n",
       "Id          \n",
       "619   2007  \n",
       "871   2009  \n",
       "93    2009  \n",
       "818   2008  \n",
       "303   2006  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f3af8",
   "metadata": {},
   "source": [
    "### Creating the pipeline\n",
    "\n",
    "First we define the preproessing steps which describe how we handle the missing data and how we want to transform the categorical data into numerical data. In this step, we pick the model (in our case it is `XGBRegressor()`).Lastly, we bundle everything together into a ML Pipeline which we call `model_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb4cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "ord_categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown=\"use_encoded_value\",\n",
    "                               unknown_value=np.nan,\n",
    "                               categories=specified_ordering))\n",
    "])\n",
    "\n",
    "ohe_categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat_ord', ord_categorical_transformer, ord_categorical_cols),\n",
    "        ('cat_ohe', ohe_categorical_transformer, ohe_categorical_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Define model\n",
    "#model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "#model = XGBClassifier(eval_metric='logloss', seed=7) \n",
    "model = XGBRegressor()\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('xgbrg', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351ba027",
   "metadata": {},
   "source": [
    "## Parameter tuning\n",
    "\n",
    "In the cell below we supply `model_pipeline` to `GridSearchCV` in order to optimise over a range of parameters specified in `param_grid`. We use the best choice of parameters to train the model on our training data and then predict the `Price` for houses in the validation data-set. Lastly, we provide the Mean Absolute Error (MAE) as a measure to how well our model is doing (the lower the MAE, the better the model is). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e12ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters {'xgbrg__learning_rate': 0.055, 'xgbrg__n_estimators': 500}\n",
      "MAE: 15928.752809289384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"xgbrg__n_estimators\": [500, 550, 570],\n",
    "    \"xgbrg__learning_rate\": [0.045, 0.05, 0.055],\n",
    "}\n",
    "\n",
    "# TODO: incorporate early stopping\n",
    "fit_params = {\"xgbrg__eval_set\": [(X_valid, y_valid)],\n",
    "              \"xgbrg__early_stopping_rounds\": 5,\n",
    "              \"xgbrg__verbose\": False\n",
    "}\n",
    "\n",
    "searchCV = GridSearchCV(model_pipeline, cv=2, param_grid = param_grid)\n",
    "\n",
    "# Fit model \n",
    "searchCV.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Validation data, get predictions\n",
    "print(\"Optimal parameters\",searchCV.best_params_) \n",
    "preds = searchCV.predict(X_valid)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "print('MAE:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab66de6",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "To conclude, we predict the `Price` for the houses in the testing dataset using all the training data available and write the predictions to `submission.csv` in order to submit to a Kaggle Competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7386ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model for deployment\n",
    "searchCV.fit(X_deploy, y_deploy)\n",
    "\n",
    "# Preprocessing of test data, fit model\n",
    "preds_test = searchCV.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0187db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7abb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
